{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPyucq5r/zsVIt1q2GxLLjf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ym001/distancia/blob/master/notebook/textDistance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install distancia==0.0.53\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQA833f5YAUv",
        "outputId": "6ea249cd-4a3b-463e-8384-4cb07d528803"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting distancia==0.0.53\n",
            "  Downloading distancia-0.0.53-py3-none-any.whl.metadata (15 kB)\n",
            "Downloading distancia-0.0.53-py3-none-any.whl (93 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.8/93.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: distancia\n",
            "  Attempting uninstall: distancia\n",
            "    Found existing installation: distancia 0.0.52\n",
            "    Uninstalling distancia-0.0.52:\n",
            "      Successfully uninstalled distancia-0.0.52\n",
            "Successfully installed distancia-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWK5aK5CX8M-",
        "outputId": "5fec4262-4338-4cae-be68-6ce8acaa94a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1.5+0j), (0.2381966011250105+0.1902113032590307j), (0.2999999999999998+0j), (0.36180339887498947-0.1902113032590307j), 0]\n",
            "TF-IDF Similarity: 0.9999999999999999\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "from typing import List, Dict\n",
        "from collections import Counter\n",
        "from distancia import TFIDFDistance\n",
        "\n",
        "# Exemple d'utilisation\n",
        "corpus = [\n",
        "    \"the cat sat on the mat\",\n",
        "    \"the dog sat on the mat\",\n",
        "    \"the dog chased the cat\"\n",
        "]\n",
        "\n",
        "text1 = \"the cat is sitting on the mat\"\n",
        "text2 = \"the dog is sitting on the mat\"\n",
        "\n",
        "tfidf_distance = TFIDFDistance(corpus)\n",
        "similarity_score: float = tfidf_distance.compare(text1, text2)\n",
        "\n",
        "print(f\"TF-IDF Similarity: {similarity_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Set\n",
        "from distancia import OverlapCoefficient\n",
        "\n",
        "# Exemple d'utilisation\n",
        "set1 = {\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"}\n",
        "set2 = {\"the\", \"dog\", \"sat\", \"on\", \"the\", \"mat\"}\n",
        "\n",
        "overlap = OverlapCoefficient()\n",
        "similarity_score: float = overlap.compute(set1, set2)\n",
        "\n",
        "print(f\"Overlap Coefficient: {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w8XSppbrwuR",
        "outputId": "f778aa3b-d87d-49da-867e-d78c1af79590"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overlap Coefficient: 0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "from collections import Counter\n",
        "import math\n",
        "from distancia import Euclidean,BagOfWordsDistance\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Exemple d'utilisation\n",
        "text1 = \"the cat sat on the mat\"\n",
        "text2 = \"the dog sat on the mat\"\n",
        "\n",
        "bow_distance = BagOfWordsDistance()\n",
        "similarity_score: float = bow_distance.compute(text1, text2)\n",
        "\n",
        "print(f\"Bag-of-Words Distance: {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "BeBtlh6J2Ga7",
        "outputId": "c05716f5-34f1-4b3d-8e51-ac5f7cea9bd2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Euclidean' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1df183d79efc>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mbow_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBagOfWordsDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msimilarity_score\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbow_distance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Bag-of-Words Distance: {similarity_score}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/distancia/textDistance.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, text1, text2)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[0;31m# Calcul de la distance entre les deux vecteurs (utilisation de la distance euclidienne ici)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m         \u001b[0mdistance\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Euclidean' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distancia import Cosine,FastTextDistance\n",
        "\n",
        "from typing import List, Dict\n",
        "from gensim.models import FastText\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "\n",
        "# Exemple d'utilisation\n",
        "# Supposons que vous avez un modèle FastText pré-entraîné\n",
        "# model = FastText.load(\"fasttext_model.bin\")  # Charger un modèle FastText pré-entraîné\n",
        "\n",
        "# Pour l'exemple, nous créons un modèle simple avec un corpus minimal\n",
        "sentences = [[\"the\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"], [\"the\", \"dog\", \"sat\", \"on\", \"the\", \"mat\"]]\n",
        "model = FastText(sentences, vector_size=100, window=5, min_count=1, sg=1)\n",
        "\n",
        "text1 = \"the cat sat on the mat\"\n",
        "text2 = \"the dog sat on the mat\"\n",
        "\n",
        "fasttext_distance = FastTextDistance(model)\n",
        "distance: float = fasttext_distance.compute(text1, text2)\n",
        "\n",
        "print(f\"FastText Distance: {distance}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pEAsF813xv9",
        "outputId": "8a14e90c-96b9-4678-8327-d0143fb7ec88"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText Distance: 0.8791867617985321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Set\n",
        "from distancia import NgramDistance\n",
        "\n",
        "# Exemple d'utilisation\n",
        "ngram_distance = NgramDistance(n=3)  # Tri-grammes (n=3)\n",
        "\n",
        "text1: str = \"The quick brown fox\"\n",
        "text2: str = \"The quick brown dog\"\n",
        "\n",
        "distance: float = ngram_distance.compute(text1, text2)\n",
        "print(f\"N-gram Distance: {distance}\")\n"
      ],
      "metadata": {
        "id": "cBGAVJze-e-A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6397be2-20b7-4342-f3a1-8d4e644fe866"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N-gram Distance: 0.3529411764705882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "from distancia import SmithWaterman\n",
        "\n",
        "# Exemple d'utilisation\n",
        "seq1: str = \"AGACTG\"\n",
        "seq2: str = \"GACTTAC\"\n",
        "\n",
        "sw = SmithWaterman(match_score=2, mismatch_penalty=-1, gap_penalty=-2)\n",
        "\n",
        "# Calcul de la distance\n",
        "max_score, score_matrix = sw.compute(seq1, seq2)\n",
        "print(f\"Max Alignment Score: {max_score}\")\n",
        "\n",
        "# Effectuer le traceback\n",
        "aligned_seq1, aligned_seq2 = sw.traceback(score_matrix, seq1, seq2)\n",
        "print(f\"Aligned Sequence 1: {aligned_seq1}\")\n",
        "print(f\"Aligned Sequence 2: {aligned_seq2}\")\n"
      ],
      "metadata": {
        "id": "QPXCorF2_Alt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dfc4df-e66e-4d12-db50-919036adb178"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Alignment Score: 8\n",
            "Aligned Sequence 1: GACT\n",
            "Aligned Sequence 2: GACT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from distancia import Levenshtein\n",
        "from typing import List, Callable\n",
        "\n",
        "\n",
        "# Exemple d'utilisation\n",
        "text1: str = \"the quick brown fox\"\n",
        "text2: str = \"the quick brown dog\"\n",
        "\n",
        "# Convertir les textes en listes de mots\n",
        "set1: List[str] = text1.split()\n",
        "set2: List[str] = text2.split()\n",
        "\n",
        "# Créer une instance de la classe Monge-Elkan avec la distance de Levenshtein comme distance de base\n",
        "monge_elkan = MongeElkanDistance(base_distance=Levenshtein())\n",
        "\n",
        "# Calculer la distance Monge-Elkan\n",
        "distance: float = monge_elkan.compute(set1, set2)\n",
        "print(f\"Monge-Elkan Distance: {distance}\")\n"
      ],
      "metadata": {
        "id": "fYGEwXA3_f2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "6e49e598-d988-43b7-ec75-39d4b7da4bc0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'MongeElkanDistance' from 'distancia' (/usr/local/lib/python3.10/dist-packages/distancia/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-10944d41ce64>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdistancia\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLevenshtein\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMongeElkanDistance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Exemple d'utilisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'MongeElkanDistance' from 'distancia' (/usr/local/lib/python3.10/dist-packages/distancia/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "class JensenShannonDivergence:\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"\n",
        "        Initialise la classe Jensen-Shannon Divergence.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def compute(self, dist1: List[float], dist2: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        Calcule la Jensen-Shannon Divergence entre deux distributions de probabilités.\n",
        "\n",
        "        :param dist1: Première distribution de probabilités (somme égale à 1).\n",
        "        :param dist2: Deuxième distribution de probabilités (somme égale à 1).\n",
        "        :return: La divergence Jensen-Shannon entre les deux distributions.\n",
        "        \"\"\"\n",
        "        if len(dist1) != len(dist2):\n",
        "            raise ValueError(\"Les distributions doivent avoir la même longueur\")\n",
        "\n",
        "        # Calcul de la distribution moyenne\n",
        "        avg_dist: List[float] = [(p1 + p2) / 2 for p1, p2 in zip(dist1, dist2)]\n",
        "\n",
        "        # Calcul de la divergence KL pour les deux distributions par rapport à la distribution moyenne\n",
        "        kl_div1: float = self._kl_divergence(dist1, avg_dist)\n",
        "        kl_div2: float = self._kl_divergence(dist2, avg_dist)\n",
        "\n",
        "        # La Jensen-Shannon Divergence est la moyenne des deux divergences KL\n",
        "        return (kl_div1 + kl_div2) / 2\n",
        "\n",
        "    def _kl_divergence(self, dist_p: List[float], dist_q: List[float]) -> float:\n",
        "        \"\"\"\n",
        "        Calcule la Kullback-Leibler Divergence entre deux distributions.\n",
        "\n",
        "        :param dist_p: Distribution de probabilité p.\n",
        "        :param dist_q: Distribution de probabilité q.\n",
        "        :return: La divergence KL entre les distributions p et q.\n",
        "        \"\"\"\n",
        "        divergence: float = 0.0\n",
        "        for p, q in zip(dist_p, dist_q):\n",
        "            if p > 0 and q > 0:\n",
        "                divergence += p * math.log(p / q)\n",
        "        return divergence\n",
        "\n",
        "    def text_to_distribution(self, text: str, vocabulary: List[str]) -> List[float]:\n",
        "        \"\"\"\n",
        "        Convertit un texte en distribution de probabilités basée sur la fréquence des mots dans un vocabulaire.\n",
        "\n",
        "        :param text: Le texte à convertir.\n",
        "        :param vocabulary: La liste des mots qui composent le vocabulaire.\n",
        "        :return: Une distribution de probabilités (liste de fréquences normalisées).\n",
        "        \"\"\"\n",
        "        # Tokenize le texte\n",
        "        word_counts: Dict[str, int] = Counter(text.split())\n",
        "\n",
        "        # Crée une distribution basée sur le vocabulaire\n",
        "        dist: List[float] = [word_counts.get(word, 0) for word in vocabulary]\n",
        "\n",
        "        # Normalise la distribution pour que la somme soit égale à 1\n",
        "        total_count: float = sum(dist)\n",
        "        if total_count > 0:\n",
        "            dist = [count / total_count for count in dist]\n",
        "\n",
        "        return dist\n",
        "\n",
        "# Exemple d'utilisation avec des textes\n",
        "text1: str = \"The quick brown fox jumps over the lazy dog\"\n",
        "text2: str = \"The fast brown fox leaps over the lazy dog\"\n",
        "\n",
        "# Vocabulaire global (tous les mots apparaissant dans les textes)\n",
        "vocabulary: List[str] = list(set(text1.split()) | set(text2.split()))\n",
        "\n",
        "# Créer une instance de la classe Jensen-Shannon Divergence\n",
        "js_divergence = JensenShannonDivergence()\n",
        "\n",
        "# Convertir les textes en distributions de probabilités\n",
        "dist1: List[float] = js_divergence.text_to_distribution(text1, vocabulary)\n",
        "dist2: List[float] = js_divergence.text_to_distribution(text2, vocabulary)\n",
        "\n",
        "# Calculer la Jensen-Shannon Divergence entre les deux textes\n",
        "divergence: float = js_divergence.compute(dist1, dist2)\n",
        "print(f\"Jensen-Shannon Divergence: {divergence}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87MMdo-akDsr",
        "outputId": "5dfb2685-4a82-4c05-860e-2459a0a44e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jensen-Shannon Divergence: 0.15403270679109896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "from collections import Counter\n",
        "import math\n",
        "from distancia import BLEUScore\n",
        "\n",
        "# Exemple d'utilisation\n",
        "hypothesis: List[str] = \"the cat is on the mat\".split()\n",
        "references: List[List[str]] = [\n",
        "    \"the cat is on the mat\".split(),\n",
        "    \"there is a cat on the mat\".split()\n",
        "]\n",
        "\n",
        "# Créer une instance de la classe BLEUScore\n",
        "bleu = BLEUScore()\n",
        "\n",
        "# Calculer le BLEU Score\n",
        "score: float = bleu.compute(hypothesis, references)\n",
        "print(f\"BLEU Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZhpRoPi9205",
        "outputId": "b3a0553d-596f-4c38-8740-3fcfc2e96f8f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple, Dict\n",
        "from collections import Counter\n",
        "\n",
        "from distancia import ROUGEScore\n",
        "\n",
        "# Example usage:\n",
        "hypothesis: List[str] = \"the cat is on the mat\".split()\n",
        "references: List[List[str]] = [\n",
        "    \"the cat is on the mat\".split(),\n",
        "    \"there is a cat on the mat\".split()\n",
        "]\n",
        "\n",
        "# Create an instance of the ROUGEScore class with bigrams (n=2)\n",
        "rouge = ROUGEScore(n_gram=2)\n",
        "\n",
        "# Compute the ROUGE-N score\n",
        "rouge_n_score: Dict[str, float] = rouge.rouge_n(hypothesis, references)\n",
        "print(f\"ROUGE-N Score: {rouge_n_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiNvZMIj-YgE",
        "outputId": "a5157e23-73a9-4dd5-ed3d-f6484c0be78a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-N Score: {'recall': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict, Tuple\n",
        "import math\n",
        "\n",
        "from distancia import SoftCosineSimilarity\n",
        "# Example usage:\n",
        "term_similarity_matrix: Dict[Tuple[str, str], float] = {\n",
        "    (\"cat\", \"cat\"): 1.0,\n",
        "    (\"cat\", \"dog\"): 0.5,\n",
        "    (\"dog\", \"dog\"): 1.0,\n",
        "    (\"mat\", \"mat\"): 1.0,\n",
        "    (\"on\", \"on\"): 1.0,\n",
        "    (\"is\", \"is\"): 1.0\n",
        "}\n",
        "\n",
        "# Create an instance of SoftCosineSimilarity with the term similarity matrix\n",
        "soft_cosine_sim = SoftCosineSimilarity(term_similarity_matrix=term_similarity_matrix)\n",
        "\n",
        "# Define two documents as lists of words\n",
        "doc1: List[str] = [\"the\", \"cat\", \"is\", \"on\", \"the\", \"mat\"]\n",
        "doc2: List[str] = [\"the\", \"dog\", \"is\", \"on\", \"the\", \"mat\"]\n",
        "\n",
        "# Compute the Soft Cosine Similarity\n",
        "similarity_score: float = soft_cosine_sim.soft_cosine(doc1, doc2)\n",
        "print(f\"Soft Cosine Similarity: {similarity_score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGRW1YxsJYgK",
        "outputId": "23886d93-1797-44a2-e4f2-1137a9415837"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft Cosine Similarity: 0.4374999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
        "from sklearn.decomposition import TruncatedSVD as LSA\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "from distancia  import TopicModelingDistance\n",
        "# Example usage:\n",
        "documents: List[str] = [\n",
        "    \"The cat sat on the mat.\",\n",
        "    \"Dogs are great companions.\",\n",
        "    \"Cats and dogs are popular pets.\",\n",
        "    \"I love my pet cat and dog.\"\n",
        "]\n",
        "\n",
        "# Initialize TopicModelingDistance with LDA and 5 topics\n",
        "topic_model_distance = TopicModelingDistance(method='LDA', num_topics=5)\n",
        "\n",
        "# Fit the model to a list of documents\n",
        "topic_model_distance.fit(documents)\n",
        "\n",
        "# Compute the distance between two new documents\n",
        "doc1: str = \"The cat sat on the mat.\"\n",
        "doc2: str = \"Dogs are great companions.\"\n",
        "distance: float = topic_model_distance.topic_distance(doc1, doc2)\n",
        "print(f\"Topic Distance (LDA): {distance}\")\n",
        "\n",
        "# You can also use LSA by changing the method\n",
        "lsa_model_distance = TopicModelingDistance(method='LSA', num_topics=5)\n",
        "lsa_model_distance.fit(documents)\n",
        "distance_lsa: float = lsa_model_distance.topic_distance(doc1, doc2)\n",
        "print(f\"Topic Distance (LSA): {distance_lsa}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv2L4rN4KLIR",
        "outputId": "153306f6-d073-4238-fee3-9a2747463cbc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic Distance (LDA): 1.060007066936174\n",
            "Topic Distance (LSA): 1.4142135623730954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple\n",
        "\n",
        "from distancia import AlignmentBasedMeasures\n",
        "# Example usage:\n",
        "text1: str = \"The quick brown fox jumps over the lazy dog\"\n",
        "text2: str = \"The quick fox jumps over a lazy dog\"\n",
        "\n",
        "# Initialize AlignmentBasedMeasures class\n",
        "alignment_measure = AlignmentBasedMeasures()\n",
        "\n",
        "# Align the texts and compute the alignment score\n",
        "aligned_texts: List[Tuple[str, str]] = alignment_measure.align_texts(text1, text2)\n",
        "score: float = alignment_measure.alignment_score(text1, text2)\n",
        "\n",
        "# Output the results\n",
        "print(\"Aligned Texts:\")\n",
        "for word1, word2 in aligned_texts:\n",
        "    print(f\"{word1:15} {word2:15}\")\n",
        "\n",
        "print(f\"\\nAlignment Score: {score}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgxrITeeKsS0",
        "outputId": "17679eb0-8564-4931-fa09-eac8868e8ee0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aligned Texts:\n",
            "The             The            \n",
            "quick           quick          \n",
            "brown           -              \n",
            "fox             fox            \n",
            "jumps           jumps          \n",
            "over            over           \n",
            "the             a              \n",
            "lazy            lazy           \n",
            "dog             dog            \n",
            "\n",
            "Alignment Score: 0.7777777777777778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple, Set, Dict\n",
        "\n",
        "from distancia import GappyNGramDistance\n",
        "# Example usage:\n",
        "text1: str = \"the quick brown fox jumps over the lazy dog\"\n",
        "text2: str = \"the fast brown fox leaps over a sleepy dog\"\n",
        "\n",
        "# Initialize GappyNGramDistance class with n=3 and gap_size=1\n",
        "gappy_ngram_distance = GappyNGramDistance(n=3, gap_size=1)\n",
        "\n",
        "# Compute the gappy n-gram similarity\n",
        "similarity_score: float = gappy_ngram_distance.gappy_ngram_similarity(text1, text2)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Gappy N-gram Similarity Score: {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cp3w2shtLGHN",
        "outputId": "5c98627c-9799-4090-d7a8-50e3ab3a1493"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gappy N-gram Similarity Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Set, Tuple\n",
        "\n",
        "from distancia import SoftJaccardSimilarity\n",
        "# Example usage:\n",
        "text1: str = \"the quick brown fox jumps over the lazy dog\"\n",
        "text2: str = \"the fast brown fox leaps over a sleepy dog\"\n",
        "\n",
        "# Initialize SoftJaccardSimilarity class with a threshold of 0.5 (50% similarity for matching)\n",
        "soft_jaccard = SoftJaccardSimilarity(threshold=0.5)\n",
        "\n",
        "# Compute the soft Jaccard similarity\n",
        "similarity_score: float = soft_jaccard.soft_jaccard_similarity(text1, text2)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Soft Jaccard Similarity Score: {similarity_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5stjJz9uLfHW",
        "outputId": "22952942-8f63-4c4c-e131-d19234f29429"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft Jaccard Similarity Score: 0.4167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zlib\n",
        "from typing import Tuple\n",
        "\n",
        "from distancia import NormalizedCompressionDistance\n",
        "# Example usage:\n",
        "text1: str = \"the quick brown fox jumps over the lazy dog\"\n",
        "text2: str = \"the fast brown fox leaps over a sleepy dog\"\n",
        "\n",
        "# Initialize the NCD class\n",
        "ncd_calculator = NormalizedCompressionDistance()\n",
        "\n",
        "# Compute the NCD between two texts\n",
        "ncd_value: float = ncd_calculator.ncd(text1, text2)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Normalized Compression Distance (NCD): {ncd_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXaqxAoTL0u2",
        "outputId": "1e58545e-acd4-4da1-d0d0-869fd856cc8e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Compression Distance (NCD): 0.4200\n"
          ]
        }
      ]
    }
  ]
}