@book{dimensionalityreductionandscaling3,
  title={Metric learning},
  author={Bellet, Aur{\'e}lien and Habrard, Amaury and Sebban, Marc},
  year={2015},
  publisher={Morgan \& Claypool Publishers}
}
@book{dimensionalityreductionandscaling2,
  title={Multidimensional scaling},
  author={Cox, Trevor F and Cox, Michael AA},
  year={2000},
  publisher={CRC press}
}
@article{dimensionalityreductionandscaling1,
  title={A global geometric framework for nonlinear dimensionality reduction},
  author={Tenenbaum, Joshua B and Silva, Vin de and Langford, John C},
  journal={science},
  volume={290},
  number={5500},
  pages={2319--2323},
  year={2000},
  publisher={American Association for the Advancement of Science}
}
@book{comparisonandvalidation3,
  title={The elements of statistical learning: data mining, inference, and prediction},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume={2},
  year={2009},
  publisher={Springer}
}

@InProceedings{comparisonandvalidation2,
author={Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
editor={Van den Bussche, Jan and Vianu, Victor},
title={On the Surprising Behavior of Distance Metrics in High Dimensional Space},
booktitle={Database Theory --- ICDT 2001},
year={2001},
publisher={Springer Berlin Heidelberg},
address={Berlin, Heidelberg},
pages={420--434},
abstract={In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a effciency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lknorm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric L(1norm) is consistently more preferable than the Euclidean distance metric L(2norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lknorm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.},
isbn={978-3-540-44503-6}
}

@misc{comparisonandvalidation1,
  title={Algorithms for clustering data},
  author={Jain, AK},
  year={1988},
  publisher={Prentice Hall}
}
@book{statisticalanalysis2,
  title={Introduction to data mining},
  author={Mining, What Is Data},
  year={2006},
  publisher={Springer}
}

@article{statisticalanalysis1,
  title={Cluster analysis, Wiley},
  author={Everitt, BS and Landau, S and Leese, M and Stahl, D},
  journal={Chichester, UK},
  year={2011}
}

@article{GraphEditDistance,
  title={A survey of graph edit distance},
  author={Gao, Xinbo and Xiao, Bing and Tao, Dacheng and Li, Xuelong},
  journal={Pattern Analysis and applications},
  volume={13},
  pages={113--129},
  year={2010},
  publisher={Springer}
}

@incollection{shortestpath,
  title={A note on two problems in connexion with graphs},
  author={Dijkstra, Edsger W},
  booktitle={Edsger Wybe Dijkstra: his life, work, and legacy},
  pages={287--290},
  year={2022}
}

@article{frobeniusdistance,
  title={Matrix computations, 4th},
  author={Golub, Gene H and Van Loan, Charles F},
  journal={Johns Hopkins},
  year={2013}
}

@article{communitystructuredistance,
  title={Fast unfolding of communities in large networks},
  author={Blondel, Vincent D and Guillaume, Jean-Loup and Lambiotte, Renaud and Lefebvre, Etienne},
  journal={Journal of statistical mechanics: theory and experiment},
  volume={2008},
  number={10},
  pages={P10008},
  year={2008},
  publisher={IOP Publishing}
}

@article{degreedistributiondistance1,
  title={Emergence of scaling in random networks},
  author={Barabasi, Albert-Laszlo and Albert, Reka},
  journal={science},
  volume={286},
  number={5439},
  pages={509--512},
  year={1999},
  publisher={American Association for the Advancement of Science}
}

@article{degreedistributiondistance2,
author = {Newman, M. E. J.},
title = {The Structure and Function of Complex Networks},
journal = {SIAM Review},
volume = {45},
number = {2},
pages = {167-256},
year = {2003},
doi = {10.1137/S003614450342480},
URL = {https://doi.org/10.1137/S003614450342480},
eprint = {https://doi.org/10.1137/S003614450342480}
}

@ARTICLE{graphcompressiondistance,
  author={Cilibrasi, R. and Vitanyi, P.M.B.},
  journal={IEEE Transactions on Information Theory}, 
  title={Clustering by compression}, 
  year={2005},
  volume={51},
  number={4},
  pages={1523-1545},
  doi={10.1109/TIT.2005.844059}}

@article{patternbaseddistance,
  title={Network motifs: simple building blocks of complex networks},
  author={Milo, Ron and Shen-Orr, Shai and Itzkovitz, Shalev and Kashtan, Nadav and Chklovskii, Dmitri and Alon, Uri},
  journal={Science},
  volume={298},
  number={5594},
  pages={824--827},
  year={2002},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{graphkerneldistance1,
  title={On graph kernels: Hardness results and efficient alternatives},
  author={G{\"a}rtner, Thomas and Flach, Peter and Wrobel, Stefan},
  booktitle={Learning Theory and Kernel Machines: 16th Annual Conference on Learning Theory and 7th Kernel Workshop, COLT/Kernel 2003, Washington, DC, USA, August 24-27, 2003. Proceedings},
  pages={129--143},
  year={2003},
  organization={Springer}
}

@INPROCEEDINGS{graphkerneldistance2,
  author={Borgwardt, K.M. and Kriegel, H.P.},
  booktitle={Fifth IEEE International Conference on Data Mining (ICDM'05)}, 
  title={Shortest-path kernels on graphs}, 
  year={2005},
  volume={},
  number={},
  pages={8},
  doi={10.1109/ICDM.2005.132}}

@INPROCEEDINGS{diffusion2,
  author={Ghosh, Arpita and Boyd, Stephen},
  booktitle={Proceedings of the 45th IEEE Conference on Decision and Control}, 
  title={Growing Well-connected Graphs}, 
  year={2006},
  volume={},
  number={},
  pages={6605-6611},
  doi={10.1109/CDC.2006.377282}}

@article{diffusion1,
title = {Random walks and diffusion on networks},
journal = {Physics Reports},
volume = {716-717},
pages = {1-58},
year = {2017},
note = {Random walks and diffusion on networks},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2017.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0370157317302946},
author = {Naoki Masuda and Mason A. Porter and Renaud Lambiotte},
keywords = {Random walk, Network, Diffusion, Markov chain, Point process},
}

@article{comparingrandomwalkstationarydistributions3,
  title={Hitting and commute times in large random neighborhood graphs},
  author={Von Luxburg, Ulrike and Radl, Agnes and Hein, Matthias},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1751--1798},
  year={2014},
  publisher={JMLR. org}
}

@InProceedings{comparingrandomwalkstationarydistributions2,
author={Pons, Pascal and Latapy, Matthieu},
editor={Yolum, pInar and Gungor, Tunga and Gurgen, Fikret and Ozturan, Can},
title={Computing Communities in Large Networks Using Random Walks},
booktitle={Computer and Information Sciences - ISCIS 2005},
year={2005},
publisher={Springer Berlin Heidelberg},
address={Berlin, Heidelberg},
pages={284--293},
isbn={978-3-540-32085-2}
}

@article{comparingrandomwalkstationarydistributions1,
  title={Random walks on graphs},
  author={Lovasz, Laszlo},
  journal={Combinatorics, Paul erdos is eighty},
  volume={2},
  number={1-46},
  pages={4},
  year={1993}
}

@article{weisfeilerlehmansimilarity2,
  title={Weisfeiler-lehman graph kernels.},
  author={Shervashidze, Nino and Schweitzer, Pascal and Van Leeuwen, Erik Jan and Mehlhorn, Kurt and Borgwardt, Karsten M},
  journal={Journal of Machine Learning Research},
  volume={12},
  number={9},
  year={2011}
}

@article{weisfeilerlehmansimilarity1,
  title={The weisfeiler-lehman method and graph isomorphism testing},
  author={Douglas, Brendan L},
  journal={arXiv preprint arXiv:1101.5211},
  year={2011}
}

@book{spectraldistance1,
  title={Spectral graph theory},
  author={Chung, Fan RK},
  volume={92},
  year={1997},
  publisher={American Mathematical Soc.}
}

@article{spectraldistance2,
title = {A study of graph spectra for comparing graphs and trees},
journal = {Pattern Recognition},
volume = {41},
number = {9},
pages = {2833-2841},
year = {2008},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2008.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S0031320308000927},
author = {Richard C. Wilson and Ping Zhu},
keywords = {Graph matching, Tree matching, Shape representation, Spectrum, Features},
}

@article{bhattacharyya,
author = {Chattopadhyay, Aparna and Chattopadhyay, Asis and B-Rao, Chandrika},
year = {2004},
month = {07},
pages = {135-8},
title = {Bhattacharyya's distance measure as a precursor of genetic distance measures},
volume = {29},
journal = {Journal of biosciences},
doi = {10.1007/BF02703410}
}

@article{braycurtis,
  title={An Ordination of the Upland Forest Communities of Southern Wisconsin},
  author={J. Roger Bray and And J. T. Curtis and Departrnent},
  journal={Ecological Monographs},
  year={1957},
  volume={27},
  pages={325-349},
  url={https://api.semanticscholar.org/CorpusID:85720092}
}

@article{camberra,
    author = {Lance, G. N. and Williams, W. T.},
    title = "{A general theory of classificatory sorting strategies: II. Clustering systems}",
    journal = {The Computer Journal},
    volume = {10},
    number = {3},
    pages = {271-277},
    year = {1967},
    month = {01},
    abstract = "{Current clustering programs (i.e., non-hierarchical classificatory programs) are examined, with particular reference to the internal consistency of the methods used for initiation, allocation and reallocation. It is shown that almost all existing methods are open to serious objection, and that no method fully exploits the potentialities of such systems. The desirable properties of a clustering program are examined de novo, and suggestions made for optimum lines of further development.}",
    issn = {0010-4620},
    doi = {10.1093/comjnl/10.3.271},
    url = {https://doi.org/10.1093/comjnl/10.3.271},
    eprint = {https://academic.oup.com/comjnl/article-pdf/10/3/271/1333425/100271.pdf},
}

@article{chebyshev,
  title = {Discrete Manhattan and Chebyshev pair correlation functions in $k$ dimensions},
  author = {De Oliveira, Alexander Lai and Binder, Benjamin J.},
  journal = {Phys. Rev. E},
  volume = {102},
  issue = {1},
  pages = {012130},
  numpages = {11},
  year = {2020},
  month = {Jul},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.102.012130},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.102.012130}
}

@article{cosine,
  title={Boolean retrieval},
  author={Manning, Christopher D and Raghavan, Prabhakar and Sch{\"u}tze, Hinrich},
  journal={Introduction to information retrieval},
  pages={1--18},
  year={2008},
  publisher={Cambridge Univ. Press}
}


@ARTICLE{crossentropy,
  author={Shannon, C. E.},
  journal={The Bell System Technical Journal}, 
  title={A mathematical theory of communication}, 
  year={1948},
  volume={27},
  number={3},
  pages={379-423},
  keywords={},
  doi={10.1002/j.1538-7305.1948.tb01338.x}}


@article{czekanowskidice,
author="SORENSEN, T.",
title="A method of establishing groups of equal amplitude in plant sociology based on similarity of species content and its application to analyses of the vegetation on Danish commons",
journal="Biologiske Skrifter",
year="1948",
volume="5",
pages="1-34",
URL="https://cir.nii.ac.jp/crid/1571135649789292416"
}



@article{dameraulevenshtein,
author = {Damerau, Fred J.},
title = {A technique for computer detection and correction of spelling errors},
year = {1964},
issue_date = {March 1964},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
issn = {0001-0782},
url = {https://doi.org/10.1145/363958.363994},
doi = {10.1145/363958.363994},
abstract = {The method described assumes that a word which cannot be found in a dictionary has at most one error, which might be a wrong, missing or extra letter or a single transposition. The unidentified input word is compared to the dictionary again, testing each time to see if the words match—assuming one of these errors occurred. During a test run on garbled text, correct identifications were made for over 95 percent of these error types.},
journal = {Commun. ACM},
month = {mar},
pages = {171–176},
numpages = {6}
}


@article{dice,
 URL = {http://www.jstor.org/stable/1932409},
 author = {Lee R. Dice},
 journal = {Ecology},
 number = {3},
 pages = {297--302},
 publisher = {Wiley, Ecological Society of America},
 title = {Measures of the Amount of Ecologic Association Between Species},
 volume = {26},
 year = {1945}
}

@article{enhancedrogerstanimoto,
  title={A Computer Program for Classifying Plants: The computer is programmed to simulate the taxonomic process of comparing each case with every other case.},
  author={Rogers, David J and Tanimoto, Taffee T},
  journal={Science},
  volume={132},
  number={3434},
  pages={1115--1118},
  year={1960},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{euclidean,
  title={When is “nearest neighbor” meaningful?},
  author={Beyer, Kevin and Goldstein, Jonathan and Ramakrishnan, Raghu and Shaft, Uri},
  booktitle={Database Theory—ICDT’99: 7th International Conference Jerusalem, Israel, January 10--12, 1999 Proceedings 7},
  pages={217--235},
  year={1999},
  organization={Springer}
}

@article{fagermcgowan,
  title={Zooplankton Species Groups in the North Pacific: Co-occurrences of species can be used to derive groups whose members react similarly to water-mass types.},
  author={Fager, Edward W and McGowan, John A},
  journal={Science},
  volume={140},
  number={3566},
  pages={453--460},
  year={1963},
  publisher={American Association for the Advancement of Science}
}

@book{galoiswassersteinLoss,
  title={Topics in optimal transportation},
  author={Villani, C{\'e}dric},
  volume={58},
  year={2021},
  publisher={American Mathematical Soc.}
}

@article{generalizedjaccard,
  title={Multi-colony ant colony optimization based on generalized jaccard similarity recommendation strategy},
  author={Zhang, Dehui and You, Xiaoming and Liu, Sheng and Yang, Kang},
  journal={IEEE access},
  volume={7},
  pages={157303--157317},
  year={2019},
  publisher={IEEE}
}

@article{gower,
  title={A general coefficient of similarity and some of its properties},
  author={Gower, John C},
  journal={Biometrics},
  pages={857--871},
  year={1971},
  publisher={JSTOR}
}

@inproceedings{hamming,
 author = {Norouzi, Mohammad and Fleet, David J and Salakhutdinov, Russ R},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {F. Pereira and C.J. Burges and L. Bottou and K.Q. Weinberger},
 publisher = {Curran Associates, Inc.},
 title = {Hamming Distance Metric Learning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2012/file/59b90e1005a220e2ebc542eb9d950b1e-Paper.pdf},
 volume = {25},
 year = {2012}
}

@inproceedings{haversine,
  title={Measure distance locating nearest public facilities using Haversine and Euclidean Methods},
  author={Maria, E and Budiman, E and Taruk, M and others},
  booktitle={Journal of Physics: Conference Series},
  volume={1450},
  number={1},
  pages={012080},
  year={2020},
  organization={IOP Publishing}
}

@article{hellinger,
  title={Neue begr{\"u}ndung der theorie quadratischer formen von unendlichvielen ver{\"a}nderlichen.},
  author={Hellinger, Ernst},
  journal={Journal f{\"u}r die reine und angewandte Mathematik},
  volume={1909},
  number={136},
  pages={210--271},
  year={1909},
  publisher={De Gruyter Berlin, New York}
}

@article{inversetanimoto,
  title={Elementary mathematical theory of classification and prediction},
  journal={},
  author={Tanimoto, Taffee T},
  year={1958},
  publisher={International Business Machines Corp.}
}




@article{jaccard,
  title={{\'E}tude comparative de la distribution florale dans une portion des Alpes et des Jura},
  author={Jaccard, Paul},
  journal={Bull Soc Vaudoise Sci Nat},
  volume={37},
  pages={547--579},
  year={1901}
}

@article{jaro,
author = {Matthew A. Jaro},
title = {Advances in Record-Linkage Methodology as Applied to Matching the 1985 Census of Tampa, Florida},
journal = {Journal of the American Statistical Association},
volume = {84},
number = {406},
pages = {414--420},
year = {1989},
publisher = {ASA Website},
doi = {10.1080/01621459.1989.10478785},
URL = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1989.10478785},
eprint = { https://www.tandfonline.com/doi/pdf/10.1080/01621459.1989.10478785}
}

@article{jarowinkler,
doi = {10.1088/1757-899X/662/5/052016},
url = {https://dx.doi.org/10.1088/1757-899X/662/5/052016},
year = {2019},
month = {nov},
publisher = {IOP Publishing},
volume = {662},
number = {5},
pages = {052016},
author = {S C Cahyono},
title = {Comparison of document similarity measurements in scientific writing using Jaro-Winkler Distance method and Paragraph Vector method},
journal = {IOP Conference Series: Materials Science and Engineering},
abstract = {The purpose of this research is to study the methods of measuring the similarity of documents and tell us which is the most suitable for Indonesian Scientific Writing. This research method used was Jaro-Winkler Distance as method. Jaro-Winkler is a method that calculates the distance between strings and then measures the similarity. Doc2Vec (Paragraph Vector) is a method that aims to represent documents in vector form for comparison with the machine learning process. The results of this study compare the results of plagiarism detection between the Jaro-Winkler Distance method and the Doc2Vec method. The best measurement comparison method used is the accuracy of the comparison of documents and their speed. Using the dataset created, Doc2Vec outperformed the Jaro-Winkler Distance algorithm in comparing document similarities. Therefore, the development of a document similarity method will be easier in the future by using Doc2Vec (Paragraph Vector) in Indonesian scientific works.}
}

@article{kendalltau,
    author = {KENDALL, M. G.},
    title = "{A NEW MEASURE OF RANK CORRELATION}",
    journal = {Biometrika},
    volume = {30},
    number = {1-2},
    pages = {81-93},
    year = {1938},
    month = {06},
    issn = {0006-3444},
    doi = {10.1093/biomet/30.1-2.81},
    url = {https://doi.org/10.1093/biomet/30.1-2.81},
    eprint = {https://academic.oup.com/biomet/article-pdf/30/1-2/81/423380/30-1-2-81.pdf},
}





@article{kullbackleibler,
 ISSN = {00034851},
 URL = {http://www.jstor.org/stable/2236703},
 author = {S. Kullback and R. A. Leibler},
 journal = {The Annals of Mathematical Statistics},
 number = {1},
 pages = {79--86},
 publisher = {Institute of Mathematical Statistics},
 title = {On Information and Sufficiency},
 urldate = {2024-08-24},
 volume = {22},
 year = {1951}
}

@ARTICLE{levenshtein,
  author={Kulkarni, Ankur A. and Kiyavash, Negar},
  journal={IEEE Transactions on Information Theory}, 
  title={Nonasymptotic Upper Bounds for Deletion Correcting Codes}, 
  year={2013},
  volume={59},
  number={8},
  pages={5115-5130},
  keywords={Upper bound;Linear programming;Vectors;Integer linear programming;Arrays;Laboratories;Educational institutions;Deletion channel;hypergraphs;integer linear programming;linear programming relaxation;multiple-deletion correcting codes;nonasymptotic bounds;single-deletion correcting codes;Varshamov–Tenengolts codes},
  doi={10.1109/TIT.2013.2257917}}

@article{longestcommonsubsequence,
  title={Algorithms on Strings.},
  volume={71},
  DOI={10.1017/S0016672398219586},
  number={1},
  journal={Genetical Research},
  author={COULSON, A. F. W.},
  year={1998},
  pages={91–95}
}



@article{mahalanobistaguchi,
title = {A theoretical survey on Mahalanobis-Taguchi system},
journal = {Measurement},
volume = {136},
pages = {501-510},
year = {2019},
issn = {0263-2241},
doi = {https://doi.org/10.1016/j.measurement.2018.12.090},
url = {https://www.sciencedirect.com/science/article/pii/S0263224118312363},
author = {Zhi Peng Chang and Yan Wen Li and Nazish Fatima},
keywords = {Mahalanobis-Taguchi System, Mahalanobis distance, Signal-to-Noise Ratios, Orthogonal Arrays, Feature selection, Mahalanobis space},
abstract = {The Mahalanobis-Taguchi System (MTS) is a diagnosis and forecasting method employing Mahalanobis Distance (MD) and Taguchi’s Robust Engineering in a multidimensional system. In MTS, MD is used to construct a continuous measurement scale to discriminate observations and measure the level of abnormality of abnormal observations which compared to a group of normal observations. Therefore, MTS can handle the class imbalance problem. In addition, MTS is unique in its robustness to assess variability among all the levels of observations (noise) and evaluate significant and insignificant features which contributed to the multidimensional system by means of simplistic yet robust technique via Orthogonal Arrays (OA) and Signal-to-Noise Ratios (SNR). However, compared with the classic multivariate methods, MTS has a weaker theoretical basis. In order to promote the development and improvement of MTS theory, this paper reviews the literature related to developing and improving MTS theory. The survey presents and analyzes the research results in terms of MD, SNR, Mahalanobis Space (MS), feature selection, threshold, multi-class MTS, and comparison with other methods. Finally, a detailed analysis of the future possible research directions will be proposed to develop and improve MTS.}
}

@InProceedings{manhattan,
author={Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
journal={},
editor={Van den Bussche, Jan and Vianu, Victor},
title={On the Surprising Behavior of Distance Metrics in High Dimensional Space},
booktitle={Database Theory --- ICDT 2001},
year={2001},
publisher={Springer Berlin Heidelberg},
address={Berlin, Heidelberg},
pages={420--434},
abstract={In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a effciency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lknorm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric L(1norm) is consistently more preferable than the Euclidean distance metric L(2norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lknorm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.},
isbn={978-3-540-44503-6}
}














@Article{meanabsoluteerror,
AUTHOR = {Chai, T. and Draxler, R. R.},
TITLE = {Root mean square error (RMSE) or mean absolute error (MAE)? – Arguments against avoiding RMSE in the literature},
JOURNAL = {Geoscientific Model Development},
VOLUME = {7},
YEAR = {2014},
NUMBER = {3},
PAGES = {1247--1250},
URL = {https://gmd.copernicus.org/articles/7/1247/2014/},
DOI = {10.5194/gmd-7-1247-2014}
}


@article{meanabsolutepercentageerror,
title = {On the asymmetry of the symmetric MAPE},
journal = {International Journal of Forecasting},
volume = {15},
number = {4},
pages = {405-408},
year = {1999},
issn = {0169-2070},
doi = {https://doi.org/10.1016/S0169-2070(99)00007-2},
url = {https://www.sciencedirect.com/science/article/pii/S0169207099000072},
author = {Paul Goodwin and Richard Lawton},
keywords = {Forecasting, Error measures},
abstract = {Several authors have suggested that the use of the mean absolute percentage error (MAPE) as a measure of forecast accuracy should be avoided because they argue it treats forecast errors above the actual observation differently from those below this value. To counter this, the use of a symmetric (or modified) MAPE has been proposed. This paper shows that, in its treatment of negative and positive errors, the proposed modification is far from symmetric, particularly where these errors have large absolute values. It also shows that, under some circumstances, a non-monotonic relationship can occur between the symmetric MAPE and the absolute forecast errors.}
}


@article{meansquarederror,
author = {N. G. N. Prasad and J. N. K. Rao},
title = {The Estimation of the Mean Squared Error of Small-Area Estimators},
journal = {Journal of the American Statistical Association},
volume = {85},
number = {409},
pages = {163--171},
year = {1990},
publisher = {ASA Website},
doi = {10.1080/01621459.1990.10475320},
URL = { https://www.tandfonline.com/doi/abs/10.1080/01621459.1990.10475320},
eprint = { https://www.tandfonline.com/doi/pdf/10.1080/01621459.1990.10475320}
}

@article{motzkinstraus,
title={Maxima for Graphs and a New Proof of a Theorem of Turán},
volume={17}, DOI={10.4153/CJM-1965-053-6},
journal={Canadian Journal of Mathematics},
author={Motzkin, T. S. and Straus, E. G.},
year={1965},
pages={533–540}
} 


@article{ochiai,
author = {Meng Yu, Mingming Cheng, Zhicheng Yu and Zhiyong Li},
title = {Investigating Airbnb listings amenities relative to hotels},
journal = {Current Issues in Tourism},
volume = {25},
number = {19},
pages = {3168--3185},
year = {2022},
publisher = {Routledge},
doi = {10.1080/13683500.2020.1733497},
URL = { https://doi.org/10.1080/13683500.2020.1733497},
eprint = { https://doi.org/10.1080/13683500.2020.1733497}
}

@inproceedings{distancemetriclearning1,
 author = {Xing, Eric and Jordan, Michael and Russell, Stuart J and Ng, Andrew},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Becker and S. Thrun and K. Obermayer},
 publisher = {MIT Press},
 title = {Distance Metric Learning with Application to Clustering with Side-Information},
 url = {https://proceedings.neurips.cc/paper_files/paper/2002/file/c3e4035af2a1cde9f21e1ae1951ac80b-Paper.pdf},
 volume = {15},
 year = {2002}
}

@inproceedings{distancemetriclearning2,
 author = {Weinberger, Kilian Q and Blitzer, John and Saul, Lawrence},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Weiss and B. Sch\"{o}lkopf and J. Platt},
 publisher = {MIT Press},
 title = {Distance Metric Learning for Large Margin Nearest Neighbor Classification},
 url = {https://proceedings.neurips.cc/paper_files/paper/2005/file/a7f592cef8b130a6967a90617db5681b-Paper.pdf},
 volume = {18},
 year = {2005}
}

@article{otsuka,
author = {Sachio Otsuka, Megumi Nishiyama and Jun Kawaguchi},
title = {Constraint on the semantic flexibility in visual statistical learning},
journal = {Visual Cognition},
volume = {22},
number = {7},
pages = {865--880},
year = {2014},
publisher = {Routledge},
doi = {10.1080/13506285.2014.923548},
URL = { https://doi.org/10.1080/13506285.2014.923548},
eprint = { https://doi.org/10.1080/13506285.2014.923548}
}


@incollection{parallelanddistributedcomputation,
title = {The Structure of Parallel Algorithms},
booktitle = {The Structure of Parallel Algorithms},
editor = {Marshall C. Yovits},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {19},
pages = {65-112},
year = {1980},
issn = {0065-2458},
doi = {https://doi.org/10.1016/S0065-2458(08)60033-9},
url = {https://www.sciencedirect.com/science/article/pii/S0065245808600339},
author = {H.T. Kung},
abstract = {Publisher Summary This chapter presents many examples of parallel algorithms and studies them under a uniform framework. The chapter explains a parallel algorithm as a collection of independent task modules that can be executed in parallel and that communicate with each other during the execution of the algorithm. The chapter explains the three important attributes of a parallel algorithm and classifies parallel algorithms in terms of these attributes. Three orthogonal dimensions of the space of parallel algorithms: concurrency control, module granularity, and communication geometry. The classification of parallel algorithms corresponds naturally to that of parallel architectures. Algorithms for synchronous parallel computers are considered, where examples of algorithms using various communication geometries are presented. Algorithms for asynchronous parallel computers are also considered in the chapter. A number of techniques dealing with the difficulties arising from the asynchronous behavior of computation and the examples are mainly drawn from results in concurrent database systems. This chapter deals with the basic issues and techniques in designing parallel algorithms for various architectures. The chapter concludes that issues concerning algorithms for synchronous parallel computers are quite different from those for asynchronous parallel computers.},
}


@article{outlier,
author = {Rousseeuw, Peter J. and Hubert, Mia},
title = {Robust statistics for outlier detection},
journal = {WIREs Data Mining and Knowledge Discovery},
volume = {1},
number = {1},
pages = {73-79},
doi = {https://doi.org/10.1002/widm.2},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.2},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.2},
abstract = {Abstract When analyzing data, outlying observations cause problems because they may strongly influence the result. Robust statistics aims at detecting the outliers by searching for the model fitted by the majority of the data. We present an overview of several robust methods and outlier detection tools. We discuss robust procedures for univariate, low-dimensional, and high-dimensional data such as estimation of location and scatter, linear regression, principal component analysis, and classification. © 2011 John Wiley \& Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 73-79 DOI: 10.1002/widm.2 This article is categorized under: Algorithmic Development > Biological Data Mining Algorithmic Development > Spatial and Temporal Data Mining Application Areas > Health Care Technologies > Structure Discovery and Clustering},
year = {2011}
}



@article{pearson,
  title={VII. Note on regression and inheritance in the case of two parents},
  author={Pearson, Karl},
  journal={proceedings of the royal society of London},
  volume={58},
  number={347-352},
  pages={240--242},
  year={1895},
  url = {https://royalsocietypublishing.org/doi/abs/10.1098/rspl.1895.0041},
  publisher={The Royal Society London}
}

@inproceedings{ratcliffobershelp,
  title={Seeing what you said: How wizards use voice search results},
  author={Passonneau, Rebecca J and Epstein, Susan L and Gordon, Joshua B and Ligorio, Tiziana},
  booktitle={6th IJCAI Workshop on Knowledge and Reasoning in Practical Dialogue Systems},
  pages={81},
  url = {https://people.ict.usc.edu/~traum/Papers/proceedings.pdf#page=88},
  year={2009}
}


@INPROCEEDINGS{rogerstanimoto,
  author={Liang, Sheau-Farn Max and Tzeng, Li-Wen},
  booktitle={2012 Southeast Asian Network of Ergonomics Societies Conference (SEANES)}, 
  title={Assessing suitability of similarity coefficients in measuring human mental models}, 
  year={2012},
  pages={1-5},
  url = {https://ieeexplore.ieee.org/abstract/document/6299563},
  keywords={Sorting;Cognitive science;Humans;Indexes;Ergonomics;Statistical analysis;Training;mental model;card sorting;similarity coefficients},
  doi={10.1109/SEANES.2012.6299563}
}


@INPROCEEDINGS{russellrao,
  author={Naseem, Rashid and Maqbool, Onaiza and Muhammad, Siraj},
  booktitle={2011 15th European Conference on Software Maintenance and Reengineering}, 
  title={Improved Similarity Measures for Software Clustering}, 
  year={2011},
  pages={45-54},
  url = {https://ieeexplore.ieee.org/abstract/document/5741245},
  keywords={Clustering algorithms;Software measurement;Couplings;Software systems;Software algorithms;Loss measurement;Software Clustering;Jaccard-NM Measure;Jaccard Measure;Unbiased Ellenberg-NM Measure;Russell & Rao Measure},
  doi={10.1109/CSMR.2011.9}
}


@article{sokalmichener,
 ISSN = {00400262},
 URL = {http://www.jstor.org/stable/1217208},
 author = {Robert R. Sokal and F. James Rohlf},
 journal = {Taxon},
 number = {2},
 pages = {33--40},
 publisher = {International Association for Plant Taxonomy (IAPT)},
 title = {The Comparison of Dendrograms by Objective Methods},
 urldate = {2024-08-25},
 volume = {11},
 year = {1962}
}

@article{batchdistance,
  title={Data Mining: Concepts and},
  author={Han, Jiawei and Kamber, Micheline and Pei, Jian},
  journal={Techniques, Waltham: Morgan Kaufmann Publishers},
  year={2012},
  url = {https://homes.di.unimi.it/ceselli/IM/2012-13/slides/02-KnowYourData.pdf},
}

@article{comprehensivebenchmarking,
  title={Deep metric learning: A survey},
  author={Kaya, Mahmut and Bilge, Hasan {\c{S}}akir},
  journal={Symmetry},
  volume={11},
  number={9},
  pages={1066},
  year={2019},
  publisher={MDPI}
}

@article{contextualdynamicdistance,
  title={Using Galois lattices to represent network data},
  author={Freeman, Linton C and White, Douglas R},
  journal={Sociological methodology},
  pages={127--146},
  year={1993},
  publisher={JSTOR}
}


@inproceedings{customdistancefunction,
  title={The pyramid match kernel: Discriminative classification with sets of image features},
  author={Grauman, Kristen and Darrell, Trevor},
  booktitle={Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1},
  volume={2},
  pages={1458--1465},
  year={2005},
  organization={IEEE}
}


@book{distancematrix,
  title={Finding groups in data: an introduction to cluster analysis},
  author={Kaufman, Leonard and Rousseeuw, Peter J},
  year={2009},
  publisher={John Wiley \& Sons}
}

@article{dynamictimewarping1,
  title={Minimum prediction residual principle applied to speech recognition},
  author={Itakura, Fumitada},
  journal={IEEE Transactions on acoustics, speech, and signal processing},
  volume={23},
  number={1},
  pages={67--72},
  year={1975},
  url = {https://ieeexplore.ieee.org/abstract/document/1162641},
  publisher={IEEE}
}

@ARTICLE{dynamictimewarping2,
  author={Sakoe, H. and Chiba, S.},
  journal={IEEE Transactions on Acoustics, Speech, and Signal Processing}, 
  title={Dynamic programming algorithm optimization for spoken word recognition}, 
  year={1978},
  volume={26},
  number={1},
  pages={43-49},
  keywords={Dynamic programming;Heuristic algorithms;Fluctuations;Timing;Signal processing algorithms;Speech processing;Pattern matching;Constraint optimization;Feature extraction;Acoustics},
  doi={10.1109/TASSP.1978.1163055}
}


@article{frechet,
author = {ALT, HELMUT and GODAU, MICHAEL},
title = {COMPUTING THE FRÉCHET DISTANCE BETWEEN TWO POLYGONAL CURVES},
journal = {International Journal of Computational Geometry \& Applications},
volume = {05},
number = {01n02},
pages = {75-91},
year = {1995},
doi = {10.1142/S0218195995000064},
URL = {https://doi.org/10.1142/S0218195995000064},
eprint = { https://doi.org/10.1142/S0218195995000064},
abstract = { As a measure for the resemblance of curves in arbitrary dimensions we consider the so-called Fréchet-distance, which is compatible with parametrizations of the curves. For polygonal chains P and Q consisting of p and q edges an algorithm of runtime O(pq log(pq)) measuring the Fréchet-distance between P and Q is developed. Then some important variants are considered, namely the Fréchet-distance for closed curves, the nonmonotone Fréchet-distance and a distance function derived from the Fréchet-distance measuring whether P resembles some part of the curve Q. }
}


@article{integrateddistance,
  title={Swarm intelligence for clustering—A systematic review with new perspectives on data mining},
  author={Figueiredo, Elliackin and Macedo, Mariana and Siqueira, Hugo Valadares and Santana Jr, Clodomir J and Gokhale, Anu and Bastos-Filho, Carmelo JA},
  journal={Engineering Applications of Artificial Intelligence},
  volume={82},
  pages={313--329},
  year={2019},
URL = {https://www.sciencedirect.com/science/article/abs/pii/S0952197619300922},
  publisher={Elsevier}
}

@article{kendalltau,
    author = {KENDALL, M. G.},
    title = {A NEW MEASURE OF RANK CORRELATION},
    journal = {Biometrika},
    volume = {30},
    number = {1-2},
    pages = {81-93},
    year = {1938},
    month = {06},
    issn = {0006-3444},
    doi = {10.1093/biomet/30.1-2.81},
}

@book{sorensendice,
  title={A method of establishing groups of equal amplitude in plant sociology based on similarity of species content and its application to analyses of the vegetation on Danish commons},
  booktitle={A method },
  author={Sorensen, Thorvald Julius},
  year={1948},
  publisher={I kommission hos E. Munksgaard}
}

@article{tversky,
  title={Features of similarity.},
  author={Tversky, Amos},
  journal={Psychological review},
  volume={84},
  number={4},
  pages={327},
  year={1977},
  publisher={American Psychological Association}
}

@article{kullbackleibler,
 ISSN = {00034851},
 URL = {http://www.jstor.org/stable/2236703},
 author = {S. Kullback and R. A. Leibler},
 journal = {The Annals of Mathematical Statistics},
 number = {1},
 pages = {79--86},
 publisher = {Institute of Mathematical Statistics},
 title = {On Information and Sufficiency},
 volume = {22},
 year = {1951}
}

@article{spearman,
  title={The proof and measurement of association between two things.},
  author={Spearman, Charles},
  year={1961},
  publisher={Appleton Century Crofts}
}

@article{squaredlogarithmicerror,
  title={Robust Bayesian prediction and estimation under a squared log error loss function},
  author={Kiapour, A and Nematollahi, N},
  journal={Statistics \& probability letters},
  volume={81},
  number={11},
  pages={1717--1724},
  year={2011},
  url = {https://www.sciencedirect.com/science/article/abs/pii/S0167715211002331},
  publisher={Elsevier}
}

@article{visualization,
  title={Hierarchical clustering schemes},
  author={Johnson, Stephen C},
  journal={Psychometrika},
  volume={32},
  number={3},
  pages={241--254},
  year={1967},
  publisher={Springer}
}

@book{wasserstein,
  title={Topics in optimal transportation},
  author={Villani, Cedric},
  volume={58},
  year={2021},
  publisher={American Mathematical Soc.}
}

@article{metricfinder1,
  title={Comprehensive survey on distance/similarity measures between probability density functions},
  author={Cha, Sung-Hyuk},
  journal={City},
  volume={1},
  number={2},
  pages={1},
  url = {https://pdodds.w3.uvm.edu/research/papers/others/everything/cha2007a.pdf},
  year={2007}
}

@InProceedings{metricfinder2,
author={Aggarwal, Charu C. and Hinneburg, Alexander and Keim, Daniel A.},
editor={Van den Bussche, Jan and Vianu, Victor},
title={On the Surprising Behavior of Distance Metrics in High Dimensional Space},
booktitle={Database Theory --- ICDT 2001},
year={2001},
publisher={Springer Berlin Heidelberg},
address={Berlin, Heidelberg},
pages={420--434},
abstract={In recent years, the effect of the curse of high dimensionality has been studied in great detail on several problems such as clustering, nearest neighbor search, and indexing. In high dimensional space the data becomes sparse, and traditional indexing and algorithmic techniques fail from a effciency and/or effectiveness perspective. Recent research results show that in high dimensional space, the concept of proximity, distance or nearest neighbor may not even be qualitatively meaningful. In this paper, we view the dimensionality curse from the point of view of the distance metrics which are used to measure the similarity between objects. We specifically examine the behavior of the commonly used Lknorm and show that the problem of meaningfulness in high dimensionality is sensitive to the value of k. For example, this means that the Manhattan distance metric L(1norm) is consistently more preferable than the Euclidean distance metric L(2norm) for high dimensional data mining applications. Using the intuition derived from our analysis, we introduce and examine a natural extension of the Lknorm to fractional distance metrics. We show that the fractional distance metric provides more meaningful results both from the theoretical and empirical perspective. The results show that fractional distance metrics can significantly improve the effectiveness of standard clustering algorithms such as the k-means algorithm.},
isbn={978-3-540-44503-6}
}

@book{apicompatibility1,
  title={Architectural styles and the design of network-based software architectures},
  author={Fielding, Roy Thomas},
  year={2000},
  url = {https://www.proquest.com/openview/fc2d064044b971dda476dfb429a2b344/1?pq-origsite=gscholar&cbl=18750&diss=y},
  publisher={University of California, Irvine}
}

@article{apicompatibility2,
  title={Service-oriented design and development methodology},
  author={Papazoglou, Michael P and Van Den Heuvel, Willem-Jan},
  journal={International Journal of Web Engineering and Technology},
  volume={2},
  number={4},
  pages={412--442},
  year={2006},
  url = {https://www.inderscienceonline.com/doi/abs/10.1504/IJWET.2006.010423},
  publisher={Inderscience Publishers}
}

@book{automateddistancemetricselection,
  title={Metalearning: Applications to data mining},
  author={Brazdil, Pavel and Carrier, Christophe Giraud and Soares, Carlos and Vilalta, Ricardo},
  year={2008},
  publisher={Springer Science \& Business Media}
}

