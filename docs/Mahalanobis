Mahalanobis Distance
====================

The Mahalanobis distance is a measure of the distance between a point and a distribution, or between two points in a distribution that accounts for the correlation between the variables. It is particularly useful in identifying multivariate outliers and in classification problems.

Formula
--------
The Mahalanobis distance between a point :math:`\mathbf{x}` and a mean vector :math:`\mathbf{\mu}` with covariance matrix :math:`\mathbf{\Sigma}` is given by:

.. math::
    D_{M}(\mathbf{x}, \mathbf{\mu}) = \sqrt{(\mathbf{x} - \mathbf{\mu})^T \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu})}

Here:

- :math:`\mathbf{x}` is the point of interest.

- :math:`\mathbf{\mu}` is the mean vector of the distribution.

- :math:`\mathbf{\Sigma}` is the covariance matrix of the distribution.

- :math:`\mathbf{\Sigma}^{-1}` is the inverse of the covariance matrix.

History
--------
The Mahalanobis distance was introduced by the Indian statistician Prasanta Chandra Mahalanobis in 1936. It is a generalized distance metric that accounts for correlations between variables, making it more effective in high-dimensional spaces compared to Euclidean distance.

Mahalanobis distance is commonly used in multivariate anomaly detection, clustering, and classification tasks where understanding the variance and covariance of the data is crucial.


